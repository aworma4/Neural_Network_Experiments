{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "#print version\n",
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- ---------\n",
      "blis                0.7.9\n",
      "catalogue           2.0.8\n",
      "certifi             2021.5.30\n",
      "charset-normalizer  2.0.12\n",
      "click               8.0.4\n",
      "colorama            0.4.5\n",
      "confection          0.0.3\n",
      "contextvars         2.4\n",
      "cymem               2.0.7\n",
      "dataclasses         0.8\n",
      "idna                3.4\n",
      "immutables          0.19\n",
      "importlib-metadata  4.8.3\n",
      "importlib-resources 5.4.0\n",
      "Jinja2              3.0.3\n",
      "langcodes           3.3.0\n",
      "MarkupSafe          2.0.1\n",
      "murmurhash          1.0.9\n",
      "numpy               1.19.5\n",
      "packaging           21.3\n",
      "pathy               0.10.1\n",
      "pip                 21.2.2\n",
      "preshed             3.0.8\n",
      "pydantic            1.9.2\n",
      "pyparsing           3.0.9\n",
      "requests            2.27.1\n",
      "setuptools          58.0.4\n",
      "smart-open          6.3.0\n",
      "spacy               3.4.4\n",
      "spacy-legacy        3.0.11\n",
      "spacy-loggers       1.0.4\n",
      "srsly               2.4.5\n",
      "thinc               8.1.6\n",
      "tqdm                4.64.1\n",
      "typer               0.7.0\n",
      "typing_extensions   4.1.1\n",
      "urllib3             1.26.13\n",
      "wasabi              0.10.1\n",
      "wheel               0.37.1\n",
      "wincertstore        0.2\n",
      "zipp                3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "     -------------------------------------- 455.9/455.9 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.19.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-gpu) (22.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.50.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-gpu) (1.24.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (63.4.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.27.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (22.10.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (4.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.2)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-extractive-summarizer\n",
      "  Using cached bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: spacy in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from bert-extractive-summarizer) (3.4.4)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from scikit-learn->bert-extractive-summarizer) (1.19.5)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.4.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (6.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (8.1.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (2.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (58.0.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (0.7.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy->bert-extractive-summarizer) (1.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy->bert-extractive-summarizer) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer) (3.0.9)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from pathy>=0.3.5->spacy->bert-extractive-summarizer) (0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (0.0.3)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (0.7.9)\n",
      "Requirement already satisfied: immutables>=0.9 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from contextvars<3,>=2.4->thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (0.19)\n",
      "Requirement already satisfied: colorama in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->bert-extractive-summarizer) (0.4.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->bert-extractive-summarizer) (5.4.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy->bert-extractive-summarizer) (4.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.0.1)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp36-cp36m-win_amd64.whl (153 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp36-cp36m-win_amd64.whl (279 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (PEP 517): started\n",
      "  Building wheel for tokenizers (PEP 517): finished with status 'error'\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\AT030915\\anaconda3\\envs\\NN_Env\\python.exe' 'C:\\Users\\AT030915\\anaconda3\\envs\\NN_Env\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\AT030915\\AppData\\Local\\Temp\\tmp535pfs4d'\n",
      "       cwd: C:\\Users\\AT030915\\AppData\\Local\\Temp\\pip-install-b1l7m6ii\\tokenizers_2f6e0c41ea764602ac954b16a17853bf\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bert-extractive-summarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\at030915\\anaconda3\\lib\\site-packages (4.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: requests in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\at030915\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\at030915\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.4.4-cp36-cp36m-win_amd64.whl (12.7 MB)\n",
      "Collecting numpy>=1.15.0\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.5-cp36-cp36m-win_amd64.whl (490 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp36-cp36m-win_amd64.whl (36 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp36-cp36m-win_amd64.whl (21 kB)\n",
      "Collecting typing-extensions<4.2.0,>=3.7.4\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.10\n",
      "  Using cached spacy_legacy-3.0.11-py2.py3-none-any.whl (24 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp36-cp36m-win_amd64.whl (111 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.9.2-cp36-cp36m-win_amd64.whl (2.1 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.6-cp36-cp36m-win_amd64.whl (1.3 MB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting dataclasses<1.0,>=0.6\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Collecting contextvars<3,>=2.4\n",
      "  Using cached contextvars-2.4-py3-none-any.whl\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp36-cp36m-win_amd64.whl (7.0 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.3-py3-none-any.whl (32 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Using cached immutables-0.19-cp36-cp36m-win_amd64.whl (58 kB)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.0.1-cp36-cp36m-win_amd64.whl (14 kB)\n",
      "Installing collected packages: zipp, typing-extensions, importlib-metadata, dataclasses, colorama, catalogue, srsly, pyparsing, pydantic, numpy, murmurhash, immutables, cymem, click, wasabi, urllib3, typer, smart-open, preshed, packaging, MarkupSafe, importlib-resources, idna, contextvars, confection, charset-normalizer, blis, tqdm, thinc, spacy-loggers, spacy-legacy, requests, pathy, langcodes, jinja2, spacy\n",
      "Successfully installed MarkupSafe-2.0.1 blis-0.7.9 catalogue-2.0.8 charset-normalizer-2.0.12 click-8.0.4 colorama-0.4.5 confection-0.0.3 contextvars-2.4 cymem-2.0.7 dataclasses-0.8 idna-3.4 immutables-0.19 importlib-metadata-4.8.3 importlib-resources-5.4.0 jinja2-3.0.3 langcodes-3.3.0 murmurhash-1.0.9 numpy-1.19.5 packaging-21.3 pathy-0.10.1 preshed-3.0.8 pydantic-1.9.2 pyparsing-3.0.9 requests-2.27.1 smart-open-6.3.0 spacy-3.4.4 spacy-legacy-3.0.11 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.6 tqdm-4.64.1 typer-0.7.0 typing-extensions-4.1.1 urllib3-1.26.13 wasabi-0.10.1 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the library**\n",
    "<br><br>\n",
    "After installing the above packages, import the summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AT030915\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AT030915\\anaconda3\\lib\\site-packages\\transformers\\generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000018FE6B71C80> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13940\\2060036959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_processors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mModelProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     def __init__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36mModelProcessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mreduce_option\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0msentence_handler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSentenceHandler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12345\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     ):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\sentence_handler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentencizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000018FE6B71C80> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer,TransformerSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = '''\n",
    "        Eight people are dead following two shootings at shisha bars in the western German city of Hanau. At least five people were injured after gunmen opened fire at about 22:00 local time (21:00 GMT), police told the BBC. Police added that they are searching for the suspects, who fled the scene and are currently at large. The first shooting was at a bar in the city centre, while the second was in Hanau's Kesselstadt neighbourhood, according to local reports. Police officers and helicopters are patrolling both areas. An unknown number of gunmen killed three people at the first shisha bar, Midnight, before driving to the Arena Bar & Cafe and shooting dead another five victims, regional broadcaster Hessenschau reports. A dark-coloured vehicle was then seen leaving the scene.The motive for the attack is unclear, a police statement said. Can-Luca Frisenna, who works at a kiosk at the scene of one of the shootings said his father and brother were in the area when the attack took place. It's like being in a film, it's like a bad joke, that someone is playing a joke on us, he told Reuters.I can't grasp yet everything that has happened. My colleagues, all my colleagues, they are like my family - they can't understand it either. Hanau, in the state of Hessen, is about 25km (15 miles) east of Frankfurt. It comes four days after another shooting in Berlin, near a Turkish comedy show at the Tempodrom concert venue, which killed one person.\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Summarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14600\\2876848514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbert_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbert_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_summary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Summarizer' is not defined"
     ]
    }
   ],
   "source": [
    "bert_model = Summarizer()\n",
    "bert_summary = ''.join(bert_model(body, min_length=60))\n",
    "print(bert_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPT2_model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerSummarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14600\\4210013301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGPT2_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GPT2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformer_model_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt2-medium\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGPT2_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TransformerSummarizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "GPT2_model = TransformerSummarizer(transformer_type=\"GPT2\",transformer_model_key=\"gpt2-medium\")\n",
    "full = ''.join(GPT2_model(body, min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XLNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "full = ''.join(model(body, min_length=60))\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x000001A2201B71C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9060\\3793166875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSBertSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_processors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mModelProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     def __init__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36mModelProcessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mreduce_option\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0msentence_handler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSentenceHandler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12345\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     ):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\sentence_handler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentencizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x000001A2201B71C0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "from summarizer.sbert import SBertSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\at030915\\anaconda3\\envs\\nn_env\\lib\\site-packages (21.2.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\AT030915\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-4jw7r6xe\\\\pip.exe'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.2\n",
      "    Uninstalling pip-21.2.2:\n",
      "      Successfully uninstalled pip-21.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\AT030915\\anaconda3\\envs\\NN_Env\\python.exe' 'C:\\Users\\AT030915\\anaconda3\\envs\\NN_Env\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\AT030915\\AppData\\Local\\Temp\\tmpm_pd1gkz'\n",
      "       cwd: C:\\Users\\AT030915\\AppData\\Local\\Temp\\pip-install-x7gy00ol\\tokenizers_b019d6c6a43a42d5af50778fdb17d757\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-3.6\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-3.6\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "! pip install --su--upgrade pip\n",
    "!pip install -qU sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AT030915\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AT030915\\anaconda3\\lib\\site-packages\\transformers\\generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000023309F2A180> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13920\\3672967700.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSBertSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSBertSummarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'paraphrase-MiniLM-L6-v2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_sentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_processors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSingleModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mModelProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     def __init__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\model_processors.py\u001b[0m in \u001b[0;36mModelProcessor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mreduce_option\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0msentence_handler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSentenceHandler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12345\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     ):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\summarizer\\sentence_handler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, language)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentencizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000023309F2A180> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "from summarizer.sbert import SBertSummarizer\n",
    "\n",
    "\n",
    "model = SBertSummarizer('paraphrase-MiniLM-L6-v2')\n",
    "result = model(body, num_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Scientists say they have discovered a new species of orangutans on Indonesia's island of Sumatra.\n",
      "The population differs in several ways from the two existing orangutan species found in Sumatra and the neighboring island of Borneo.\n",
      "The orangutans were found inside North Sumatra's Batang Toru forest, the science publication Current Biology reported.\n",
      "Researchers named the new species the Tapanuli orangutan. They say the animals are considered a new species because of genetic, skeletal and tooth differences.\n",
      "Michael Kruetzen is a geneticist with the University of Zurich who has studied the orangutans for several years. He said he was excited to be part of the unusual discovery of a new great ape in the present day. He noted that most great apes are currently considered endangered or severely endangered.\n",
      "Gorillas, chimpanzees and bonobos also belong to the great ape species.\n",
      "Orangutan - which means person of the forest in the Indonesian and Malay languages - is the world's biggest tree-living mammal. The orange-haired animals can move easily among the trees because their arms are longer than their legs. They live more lonely lives than other great apes, spending a lot of time sleeping and eating fruit in the forest.\n",
      "The new study said fewer than 800 of the newly-described orangutans exist. Their low numbers make the group the most endangered of all the great ape species.\n",
      "They live within an area covering about 1,000 square kilometers. The population is considered highly vulnerable. That is because the environment which they depend on is greatly threatened by development.\n",
      "Researchers say if steps are not taken quickly to reduce the current and future threats, the new species could become extinct \"within our lifetime.\"\n",
      "Research into the new species began in 2013, when an orangutan protection group in Sumatra found an injured orangutan in an area far away from the other species. The adult male orangutan had been beaten by local villagers and died of his injuries. The complete skull was examined by researchers.\n",
      "Among the physical differences of the new species are a notably smaller head and frizzier hair. The Tapanuli orangutans also have a different diet and are found only in higher forest areas.\n",
      "There is no unified international system for recognizing new species. But to be considered, discovery claims at least require publication in a major scientific publication.\n",
      "Russell Mittermeier is head of the primate specialist group at the International Union for the Conservation of Nature. He called the finding a \"remarkable discovery.\" He said it puts responsibility on the Indonesian government to help the species survive.\n",
      "Matthew Nowak is one of the writers of the study. He told the Associated Press that there are three groups of the Tapanuli orangutans that are separated by non-protected land.He said forest land needs to connect the separated groups.\n",
      "In addition, the writers of the study are recommending that plans for a hydropower center in the area be stopped by the government.\n",
      "It also recommended that remaining forest in the Sumatran area where the orangutans live be protected.\n",
      "I'm Bryan Lynn.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('body_corpus.txt', 'r')\n",
    "#Store content in a variable:\n",
    "body = f.read()\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-12-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\\config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file tf_model.h5 from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\tf_model.h5\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\spiece.model\n",
      "loading file tokenizer.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\AT030915/.cache\\huggingface\\hub\\models--t5-base\\snapshots\\a4986abc64c580966eb8dd0ed61ceafaeb0d1d45\\config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' New species'}] [{'summary_text': 'the orangut'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "# use bart in pytorch\n",
    "summarizer = pipeline(\"summarization\")\n",
    "ptorch = summarizer(body, min_length=5, max_length=5)\n",
    "\n",
    "# use t5 in tf\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n",
    "tflow = summarizer(body, min_length=5, max_length=5)\n",
    "\n",
    "print(ptorch, tflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT_TEST",
   "language": "python",
   "name": "bert_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
